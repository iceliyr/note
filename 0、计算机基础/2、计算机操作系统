# 概述

- 操作系统的定义

  - 操作系统（Operating System， OS）是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机的工作和资源的分配；以提供给用户和其他软件方便的接口和环境；它是计算机系统中最基本的系统软件。

- 操作系统的基本特征

  - 并发：指两个或多个事件在同一时间间隔内发生。这些事件宏观上是同时发生的，但微观上是交替发生的操作系统的并发性指计算机系统中“同时”运行着多个程序，这些程序宏观上看是同时运行着的，而微观上看是交替运行的。

    - 单核CPU同一时刻只能执行一个程序，各个程序只能并发地执行

    - 多核CPU同一时刻可以同时执行多个程序，多个程序可以并行地执行

  - 共享：指系统中的资源可供内存中多个并发执行的进程共同使用

    - 互斥共享方式：系统中的某些资源，虽然可以提供给多个进程使用，但一个时间段内只允许一个进程访问该资源

    - 同时共享方式：系统中的某些资源，允许一个时间段内由多个进程“同时”对它们进行访问

  - 虚拟：指把一个物理上的实体变为若干个逻辑上的对应物。物理实体（前者）是实际存在的，而逻辑上对应物（后者）是用户感受到的。

    - 空分复用：虚拟存储

    - 时分复用：虚拟处理器

  - 异步是指，在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。

- 操作系统的发展

  - 手工操作：

  - 单道批处理：一条一条的执行

  - 多道批处理：在执行一条时，如果有资源可以为其他程序执行

  - 分时操作系统：时间片

  - 实时操作系统：响应紧急任务

  - 微机操作系统：
    - 用户、任务![img](https://api2.mubu.com/v3/document_image/ce00e523-22fa-4b96-9bf7-08f61efb745e-18846868.jpg)

  - 嵌入式：完成某个特定功能而设计的系统，或是有附加机制的系统，或是其他部分的计算机硬件与软件的结合体

  - 网络操作系统：在计算机网络环境下对网络资源进行管理和控制，实现数据通信及对网络资源的共享，为用户提供与网络资源接口的一组软件和规程的集合

  - 分布式系统：基于软件实现的一种多处理机系统，是多个处理机通过通信线路互连而构成的松耦合系统

- 操作系统的运行环境

  

  - 程序运行机制

    - 步骤：高级语言》编译成汇编语言》编译成机器语言（二进制）》处理器处理

    - 程序运行的过程其实就是CPU执行一条一条的机器指令的过程

    - 原语是一种特殊的程序，它的执行具有原子性。也就是说，这段程序的运行必须一气呵成，不可中断

  - 指令：

    - 特权指令：应用程序只能使用“非特权指令”，如：加法指令、减法指令等

    - 非特权指令：操作系统内核作为 “管理者”，有时会让CPU执行一些“特权指令”，如：内存清零指令。这些指令影响重大，只允许“管理者”——即操作系统内核来使用

    - 处于内核态时，说明此时正在运行的是内核程序，此时可以执行特权指令

    - 处于用户态时，说明此时正在运行的是应用程序，此时只能执行非特权指令

  - 处理器状态：

    - 核心态：

    - 用户态：

  - 程序：

    - 内核程序：内核是操作系统最重要最核心的部分，也是最接近硬件的部分甚至可以说，一个操作系统只要有内核就够了

    - 应用程序：普通程序员写的程序

- 中断和异常

  - “中断”：会使CPU由用户态变为内核态，使操作系统重新夺回对CPU的控制权

  - 分类![img](https://api2.mubu.com/v3/document_image/c6f75860-4c37-40a0-9826-6d5026d4a11d-18846868.jpg)

  - 原理![img](https://api2.mubu.com/v3/document_image/b1d8498c-f01d-480d-95b0-302d442ee5b1-18846868.jpg)

- 系统调用

  - “系统调用”是操作系统提供给应用程序（程序员/编程人员）使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以通过系统调用来请求获得操作系统内核的服务

- 操作系统的主要功能

  - ①进程管理，其工作主要是进程调度，在单用户单任务的情况下，处理器仅为一个用户的一个任务所独占， 进程管理的工作十分简单。但在多道程序或多用户的情况 下，组织多个作业或任务时，就要解决处理器的调度、 分配和回收等问题 。

  - ②存储管理分为几种功能：存储分配、存储共享、存储保护 、存储扩张。

  - ③设备管理分有以下功能：设备分配、设备传输控制 、设备独立性。

  - ④文件管理：文件存储空间的管理、目录管理 、文件操作管理、文件保护。

  - ⑤作业管理：责处理用户提交的任何要求。

- 操作系统的结构设计![img](./2、计算机操作系统.assets/6a18db84-eb72-4d1c-8911-b9591510cae3-18846868.jpg)



# 进程管理

- 程序：是静态的，就是个存放在磁盘里的可执行文件，就是一系列的指令集合。

- 程序运行机制（静态文件 》进程）

  - 图示![img](https://api2.mubu.com/v3/document_image/2fc9d859-5b27-4cd9-a772-3f3cf83db815-18846868.jpg)

- 服务：程序运行后 》可以生成多个进程 》进程为了完成一件事成为一个服务

- 进程的概念：是动态的，是程序的一次执行过程。

- 进程的组成：

  - PCB：![img](https://api2.mubu.com/v3/document_image/6793bab9-310c-4640-87ba-0289f0fdb214-18846868.jpg)

  - 程序段：程序代码（指令序列）

  - 数据段：运行过程产生的各种数据

- 进程的特征：![img](https://api2.mubu.com/v3/document_image/c561cbd3-1cab-4ca7-941d-c9faf9aed1b1-18846868.jpg)

- 进程的状态与转换

  

  - 状态

    

    

    - 创建态：进程正在被创建

    - 就绪态：当进程创建完成后，便进入“就绪态”，处于就绪态的进程已经具备运行条件，但由于没有空闲CPU，就暂时不能运行

    - 运行态：进程此时在CPU上运行

    - 阻塞态：在进程运行的过程中，可能会请求等待某个事件的发生（如等待某种系统资源的分配，或者等待其他进程的响应）。在这个事件发生之前，进程无法继续往下执行，此时操作系统会让这个进程下CPU，并让它进入“阻塞态”当CPU空闲时，又会选择另一个“就绪态”进程上CPU运行

    - 终止态：一个进程可以执行 exit 系统调用，请求操作系统终止该进程。此时该进程会进入“终止态”，操作系统会让该进程下CPU，并回收内存空间等资源，最后还要回收该进程的PCB。当终止进程的工作完成之后，这个进程就彻底消失了。

  - 转换![img](https://api2.mubu.com/v3/document_image/2cb532f3-7e7f-47ca-a7b3-4e4e327f3495-18846868.jpg)

- 进程的组织方式

  -  链接方式![img](https://api2.mubu.com/v3/document_image/943f436c-59a2-41d4-ad4f-e44418c42e64-18846868.jpg)

  -  索引方式![img](https://api2.mubu.com/v3/document_image/3b0c953f-6fbb-4ebd-882a-8ddc314cff29-18846868.jpg)

- 进程控制（实现状态转换）

  - 过程![img](https://api2.mubu.com/v3/document_image/442173bd-8945-4add-8b0f-b4e3550503b7-18846868.jpg)

  - 进程创建

    - 原理：

    - 1、调用就绪队列指针

    - 2、使用原语创建，执行过程只能一气呵成，期间不允许被中断![img](https://api2.mubu.com/v3/document_image/c1450ab4-37de-4035-b237-0ee416241cfc-18846868.jpg)

    - 3、原语![img](https://api2.mubu.com/v3/document_image/76c99900-41d2-4495-80bf-a4a04797e2ce-18846868.jpg)

  - 进程终止（ 就绪态/阻塞态/运行态-> 终止态）
    - 原语![img](https://api2.mubu.com/v3/document_image/9c389b14-7ab9-46b8-a79f-6c7b4ad1c685-18846868.jpg)

  - 进程阻塞（运行态    -> 阻塞态）

    - 运行态à

    - 阻塞态

    - 运行态à

    - 阻塞态

    - 原语![img](https://api2.mubu.com/v3/document_image/88e622d1-4d4b-452c-85d7-579917909989-18846868.jpg)

  - 进程唤醒（阻塞态 -> 就绪态）
    - 原语![img](https://api2.mubu.com/v3/document_image/80864deb-d063-415c-8e3b-1aa4ef2ca08e-18846868.jpg)

  - 进程切换（就绪态 <-> 运行态）
    - 原语![img](https://api2.mubu.com/v3/document_image/41e92c24-d960-4d33-b753-9066a4c56ae4-18846868.jpg)

  - 进程挂起（内存 》外存）![img](https://api2.mubu.com/v3/document_image/290496b2-e320-4740-9309-2019ce914b24-18846868.jpg)

- 进程通信（进程之间的信息交换）

  

  - 共享存储![img](https://api2.mubu.com/v3/document_image/a1ce7109-d1dd-4f19-b2cb-a84bce577533-18846868.jpg)

  -  管道通信![img](https://api2.mubu.com/v3/document_image/0bc0f459-27de-4f71-aab6-67851910972f-18846868.jpg)

  - 消息传递![img](https://api2.mubu.com/v3/document_image/07a45be8-9434-4c79-94ab-e623cc0fb961-18846868.jpg)

- 线程

  - 线程意义

    

    

    - 可以把线程理解为“轻量级进程”。

    - 线程是一个基本的CPU执行单元，也是程序执行流的最小单位。引入线程之后，不仅是进程之间可以并发，进程内的各线程之间也可以并发，从而进一步提升了系统的并发度，使得一个进程内也可以并发处理各种任务（如QQ视频、文字聊天、传文件）

    - 引入线程后，进程只作为除CPU之外的系统资源的分配单元（如打印机、内存地址空间等都是分配给进程的）。

    - 线程则作为处理机的分配单元。

  - 实现方式

    

    - 用户级

      

      - 代码![img](https://api2.mubu.com/v3/document_image/c27b4c87-119f-400b-a356-84b88f043bb1-18846868.jpg)

    - 内核级![img](https://api2.mubu.com/v3/document_image/fa36aac5-344c-4af5-8a01-f74611431b03-18846868.jpg)

  - 多线程

    

    - 一对一![img](https://api2.mubu.com/v3/document_image/361d16b0-f59c-401c-80e2-88cd6a1ca4a6-18846868.jpg)

    - 多对一![img](https://api2.mubu.com/v3/document_image/e661ffc5-b0ca-4704-857c-f9c19235090c-18846868.jpg)

    - 多对多![img](https://api2.mubu.com/v3/document_image/932d250d-4936-4210-8ade-a34052c68ca1-18846868.jpg)

- 调度（操作系统决定运行哪个作业或进程，并将其调入内存中准备执行的过程）

  

  - 概念：当有一堆任务要处理，但由于资源有限，这些事情没法同时处理。这就需要确定某种规则来决定处理这些任务的顺序

  - 层次：

    - 高级调度（作业调度）![img](https://api2.mubu.com/v3/document_image/1db9aeb7-7a8a-453b-b53a-2b8e242dc8a1-18846868.jpg)

    - 中级调度（内存调度）![img](https://api2.mubu.com/v3/document_image/7462399a-1463-41f9-95be-214af352a137-18846868.jpg)

    - 低级调度（进程调度）![img](https://api2.mubu.com/v3/document_image/a50f63b8-bbbf-4e06-8723-096e81b39f08-18846868.jpg)

- 进程调度

  - 调度时机![img](https://api2.mubu.com/v3/document_image/b079ff91-83b7-41c9-9aba-02a4e7cca33c-18846868.jpg)

  - 调度方式![img](https://api2.mubu.com/v3/document_image/50d7401f-361c-4e9d-909d-f5073466e9fe-18846868.jpg)

- 调度算法

  - 指标

    

    - 周转时间：从作业被提交给系统开始，到作业完成为止的这段时间间隔

      - 包含四个部分：

        - 作业在外存后备队列上等待作业调度（高级调度）的时间

        - 进程在就绪队列上等待进程调度（低级调度）的时间

        - 进程在CPU上执行的时间

        - 进程等待I/O操作完成的时间

        - （后三项在一个作业的整个处理过程中，可能发生多次）

  - 先来先服务![img](https://api2.mubu.com/v3/document_image/83badca6-b1fd-45c4-8c44-fedea1c9b322-18846868.jpg)

  - 最短作业优先![img](https://api2.mubu.com/v3/document_image/068a2f29-28d3-427d-8417-d722398afcbe-18846868.jpg)

  - 最高响应比优先![img](https://api2.mubu.com/v3/document_image/e6028dbb-9769-4722-9ec7-2e50615031a1-18846868.jpg)

  - 优先级调度![img](https://api2.mubu.com/v3/document_image/2db958cb-f1ff-46a4-89a6-a4890b29b7f5-18846868.jpg)

  - 时间片轮转![img](https://api2.mubu.com/v3/document_image/9afc2a6d-22f4-45e4-8c75-2315cfe60d15-18846868.jpg)

  - 多级反馈队列

    

    - 案例![img](https://api2.mubu.com/v3/document_image/9bc2cf9f-d947-4620-8bb1-ca739c116986-18846868.jpg)

- 进程的切换与过程![img](https://api2.mubu.com/v3/document_image/109ac5b2-3416-4dd1-9e7b-a17ee2f8ea34-18846868.jpg)

- 进程同步、进程互斥

  - 同步：亦称直接制约关系，它是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而产生的制约关系。进程间的直接制约关系就是源于它们之间的相互合作

  - 互斥：为了实现对临界资源的互斥访问，同时保证系统整体性能，需要遵循以下原则

    - 1. 空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区；

      

    - 2. 忙则等待。当已有进程进入临界区时，其他试图进入临界区的进程必须等待；

      

    - 3. 有限等待。对请求访问的进程，应保证能在有限时间内进入临界区（保证不会饥饿）；

      

    - 4. 让权等待。当进程不能进入临界区时，应立即释放处理机，防止进程忙等待。

      

  - 进程互斥的软件实现方法

    - 单标志法：

      - 算法思想：两个进程在 访问完临界区后 会把使用临界区的权限转交给另一个进程。也就是说每个进程进入临界区的权限只能被另一个进程赋予

      - 案例：![img](https://api2.mubu.com/v3/document_image/5b96713f-39c2-49b4-bdff-9aace8ce1a4f-18846868.jpg)

      - 缺点：只能按 P1 > P0 > P1 >……这样轮流访问。这种必须“轮流访问”带来的问题是，如果此时允许进入临界区的进程是 P0，而 P0 一直不访问临界区，那么虽然此时临界区空闲，但是并不允许 P1 访问。因此，单标志法存在的主要问题是：违背“空闲让进”原则。

    - 双标志先检查法：

      - 算法思想：设置一个布尔型数组 flag[]，数组中各个元素用来标记各进程想进入临界区的意愿，比如“flag[0] = ture”意味着 0 号进程 P0 现在想要进入临界区。每个进程在进入临界区之前先检查当前有没有别的进程想进入临界区，如果没有，则把自身对应的标志 flag[i] 设为 true，之后开始访问临界区。

      - 案例：![img](https://api2.mubu.com/v3/document_image/561e783a-c76c-4e20-96da-576f1399abcb-18846868.jpg)

      - 缺点：若按照 ①⑤②⑥③⑦….的顺序执行，P0 和 P1 将会同时访问临界区。因此，双标志先检查法的主要问题是：违反“忙则等待”原则。原因在于，进入区的“检查”和“上锁” 两个处理不是一气呵成的。“检查”后，“上锁”前可能发生进程切换。

    - 双标志后检查法：

      - 算法思想：双标志先检查法的改版。前一个算法的问题是先“检查”后“上锁”，但是这两个操作又无法一气呵成，因此导致了两个进程同时进入临界区的问题。因此，人们又想到先“上锁”后“检查”的方法，来避免上述问题。

      - 案例![img](https://api2.mubu.com/v3/document_image/2c42c46c-0db6-45f8-8321-4e0c1a29ad1c-18846868.jpg)

      - 缺点：若按照 ①⑤②⑥….的顺序执行，P0 和 P1 将都无法进入临界区因此，双标志后检查法虽然解决了“忙则等待”的问题，但是又违背了“空闲让进”和“有限等待”原则，会因各进程都长期无法访问临界资源而产生“饥饿”现象。两个进程都争着想进入临界区，但是谁也不让谁，最后谁都无法进入临界区。

    - Peterson 算法：

      - 算法思想：结合双标志法、单标志法的思想。如果双方都争着想进入临界区，那可以让进程尝试“孔融让梨”（谦让）

      - 案例![img](https://api2.mubu.com/v3/document_image/14fc7d2f-7f9d-496f-8ba3-2335aa0da336-18846868.jpg)

      - 缺点：Peterson 算法用软件方法解决了进程互斥问题，遵循了空闲让进、忙则等待、有限等待 三个原则，但是依然未遵循让权等待的原则。

  - 进程互斥的硬件实现方法

    - 中断屏蔽方法![img](https://api2.mubu.com/v3/document_image/7f08a2ee-7e6d-4a84-81e8-f7cb7a0fd9c4-18846868.jpg)

    - TestAndSet 指令![img](https://api2.mubu.com/v3/document_image/6f98011a-dcd0-4b7c-a46e-335e3a5e28ea-18846868.jpg)

    - Swap 指令![img](https://api2.mubu.com/v3/document_image/34b831cd-82de-4b8c-95ce-fcdb88ccb82a-18846868.jpg)

  - 信号量  

    

    - 定义、作用、应用

      - 信号量其实就是一个变量 ，可以用一个信号量来表示系统中某种资源的数量，比如：系统中只有一台打印机，就可以设置一个初值为 1 的信号量。

      - 用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而很方便的实现了进程互斥、进程同步。

      - 原语是一种特殊的程序段，其执行只能一气呵成，不可被中断。原语是由关中断/开中断指令实现的。软件解决方案的主要问题是由“进入区的各种操作无法一气呵成”，因此如果能把进入区、退出区的操作都用“原语”实现，使这些操作能“一气呵成”就能避免问题。

    - 一对原语：wait(S) 原语和 signal(S) 原语，可以把原语理解为我们自己写的函数，函数名分别为 wait和 signal，括号里的信号量 S 其实就是函数调用时传入的一个参数。

      - wait、signal 原语常简称为 P、V操作（来自荷兰语 proberen 和 verhogen）。

      - 因此，做题的时候常把wait(S)、signal(S) 两个操作分别写为 P(S)、V(S)

    -  整型信号量![img](https://api2.mubu.com/v3/document_image/b73694e7-757e-4304-8c4e-5ee6f2fb8d2f-18846868.jpg)

    -  记录型信号量

      

      - 原理![img](https://api2.mubu.com/v3/document_image/9bee5ae9-cfb9-4c16-b3c5-7d8895d76a02-18846868.jpg)

  - PV原语问题：

    - 生产者-消费者

    - 多生产者-多消费者

    - 吸烟者

    - 读者-写者：[读者写者问题](https://blog.csdn.net/aimat2020/article/details/121692122)

  - 用信号量机制实现进程互斥、同步、前驱关系死锁

    

    - 信号量机制实现进程互斥![img](https://api2.mubu.com/v3/document_image/feee29b4-291f-4481-baf0-d59f3ecd053e-18846868.jpg)

    - 信号量机制实现进程同步![img](https://api2.mubu.com/v3/document_image/5a33fbcc-9821-4f69-9743-29c3244b7a5f-18846868.jpg)

    - 信号量机制实现前驱关系![img](https://api2.mubu.com/v3/document_image/58a5c095-ecc7-4e25-b2cc-6f3bccf47da0-18846868.jpg)

- 死锁

  - 死锁：各进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象

  - 死锁产生的必要条件

    - 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁（如哲学家的筷子、打印机设备）。像内存、扬声器这样可以同时让多个进程使用的资源是不会导致死锁的（因为进程不用阻塞等待这种资源）。

    - 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。

    - 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。

    - 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。

  - 死锁产生的时机

    - 1. 对系统资源的竞争。各进程对不可剥夺的资源（如打印机）的竞争可能引起死锁，对可剥夺的资源（CPU）的竞争是不会引起死锁的。

      

    - 2. 进程推进顺序非法。请求和释放资源的顺序不当，也同样会导致死锁。例如，并发执行的进程P1、P2 分别申请并占有了资源 R1、R2，之后进程P1又紧接着申请资源R2，而进程P2又申请资源R1，两者会因为申请的资源被对方占有而阻塞，从而发生死锁。

      

    - 3. 信号量的使用不当也会造成死锁。如生产者-消费者问题中，如果实现互斥的P操作在实现同步的P操作之前，就有可能导致死锁。（可以把互斥信号量、同步信号量也看做是一种抽象的系统资源）

      

  - 死锁的处理策略

    - 不允许死锁发生

      - 静态策略（预防死锁）

        

        - 破坏互斥条件![img](https://api2.mubu.com/v3/document_image/c5cfc3e2-108a-4180-ac11-505791383135-18846868.jpg)

        - 破坏不剥夺条件![img](https://api2.mubu.com/v3/document_image/9b581758-a271-4518-afe0-40283c1ba607-18846868.jpg)

        - 破坏请求和保持条件 ![img](https://api2.mubu.com/v3/document_image/d101d566-d23e-4b00-bcb7-7425a8feba51-18846868.jpg)

        - 破坏循环等待条件![img](https://api2.mubu.com/v3/document_image/2870b05a-3af8-4bf0-918d-33eec73cbbce-18846868.jpg)

      - 动态策略（避免死锁）

        - 安全序列：指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态。当然，安全序列可能有多个。

        - 如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后可能所有进程都无法顺利的执行下去。当然，如果有进程提前归还了一些资源，那系统也有可能重新回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况。

        - 如果系统处于安全状态，就一定不会发生死锁。如果系统进入不安全状态，就可能发生死锁（处于不安全状态未必就是发生了死锁，但发生死锁时一定是在不安全状态）

        - 因此可以在资源分配之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求。这也是“银行家算法”的核心思想。![img](https://api2.mubu.com/v3/document_image/283229f7-78a1-4854-9887-03f9512fdde9-18846868.jpg)

    - 允许死锁发生

      

      - ①死锁检测算法：用于检测系统状态，以确定系统中是否发生了死锁

        - 检测死锁的算法：

          

          - 1）在资源源分配图中，找出既不阻塞又不是孤点的进程 Pi（即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。如下图中，R1没有空闲资源，R2有一个空闲资源。若所有的连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源）。消去它所有的请求边和分配变，使之称为孤立的结点。在下图中，P1 是满足这一条件的进程结点，于是将P1的所有边消去。

          - 2）进程 Pi 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在下图中，P2 就满足这样的条件。根据 1）中的方法进行一系列简化后，若能消去途中所有的边，则称该图是可完全简化的。

        - 死锁定理：如果某时刻系统的资源分配图是不可完全简化的，那么此时系统死锁

      - ②死锁解除算法：当认定系统中已经发生了死锁，利用该算法可将系统从死锁状态中解脱出来（并不是系统中所有的进程都是死锁状态，用死锁检测算法化简资源分配图后，还连着边的那些进程就是死锁进程）

        - 方法策略

          - 1. 资源剥夺法。挂起（暂时放到外存上）某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但是应防止被挂起的进程长时间得不到资源而饥饿。

            

          - 2. 撤销进程法（或称终止进程法）。强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。这种方式的优点是实现简单，但所付出的代价可能会很大。因为有些进程可能已经运行了很长时间，已经接近结束了，一旦被终止可谓功亏一篑，以后还得从头再来。

            

          - 3. 进程回退法。让一个或多个死锁进程回退到足以避免死锁的地步。这就要求系统要记录进程的历史信息，设置还原点。

            

        - 解除选择

          - 1. 进程优先级

            

          - 2. 已执行多长时间

            

          - 3. 还要多久能完成

            

          - 4. 进程已经使用了多少资源

            

          - 5. 进程是交互式的还是批处理式的

            

# 内存管理

- 从写程序到程序运行（程序的产生到运行）

  - 步骤![img](https://api2.mubu.com/v3/document_image/9e7bbe58-7de9-4f8c-b27f-4c3619b76a72-18846868.jpg)

  - 归纳![img](https://api2.mubu.com/v3/document_image/d815ea86-e10f-41c3-90a0-5b8fd2cf4b04-18846868.jpg)

  - 编译：由编译程序将用户源代码编译成若干个目标模块（编译就是把高级语言翻译为机器语言）

  - 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块

    - 链接方式：

      - 静态链接：在程序运行之前，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开![img](https://api2.mubu.com/v3/document_image/0f820b74-093e-458e-b588-54792420a78e-18846868.jpg)

      - 装入时动态链接：将各目标模块装入内存时，边装入边链接的链接方式![img](https://api2.mubu.com/v3/document_image/c2eb220e-1188-4ccb-b39d-6d5080b4c745-18846868.jpg)

      - 运行时动态链接：在程序执行中需要该目标模块时，才对它进行链接。其优点是便于修改和更新，便于实现对目标模块的共享![img](https://api2.mubu.com/v3/document_image/0107fb5c-161b-404a-a6c6-41d5f002b506-18846868.jpg)

  - 装入（装载）：由装入程序将装入模块装入内存运行

    - 逻辑地址/物理地址![img](https://api2.mubu.com/v3/document_image/22b25858-0c87-4a63-bbd2-6589f78a094d-18846868.jpg)

    - 装入方式

      - 绝对装入：在编译时，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码。装入程序按照装入模块中的地址，将程序和数据装入内存![img](https://api2.mubu.com/v3/document_image/a4ba5e94-00a2-4785-bf01-889f14aebe07-18846868.jpg)

      - 静态重定位：又称可重定位装入。编译、链接后的装入模块的地址都是从0开始的，指令中使用的地址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对地址进行“重定位”，将逻辑地址变换为物理地址（地址变换是在装入时一次完成的）![img](https://api2.mubu.com/v3/document_image/0883436a-8e62-417f-a8d4-7f0855967f3a-18846868.jpg)

      - 动态重定位：又称动态运行时装入。编译、链接后的装入模块的地址都是从0开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要执行时才进行。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个重定位寄存器的支持。![img](https://api2.mubu.com/v3/document_image/35abb286-3bf7-4238-9831-e2b4722e1c51-18846868.jpg)

- 内存空间的分配与回收

  - 内部碎片/外部碎片

    - 内部碎片，分配给某进程的内存区域中，如果有些部分没有用上。

    - 外部碎片，是指内存中的某些空闲分区由于太小而难以利用。

  - 局部性原理：![img](https://api2.mubu.com/v3/document_image/a537dea8-7e93-43f4-a925-4b40bd0fa009-18846868.jpg)

  - 连续分配：进程分配是一个连续的内存空间

    - 单一连续分配（单用户单任务）![img](https://api2.mubu.com/v3/document_image/00d896d7-945d-46f9-bb7b-dc1ddd9f0b8c-18846868.jpg)

    - 固定分区分配

      - 方式：

        

        - 分区大小相等：缺乏灵活性，但是很适合用于用一台计算机控制多个相同对象的场合（比如：钢铁厂有n个相同的炼钢炉，就可把内存分为n个大小相等的区域存放n个炼钢炉控制程序）

        - 分区大小不等：增加了灵活性，可以满足不同大小的进程需求。根据常在系统中运行的作业大小情况进行划分（比如：划分多个小分区、适量中等分区、少量大分区）

      - 分区说明表：

        - 每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小、起始地址、状态![img](https://api2.mubu.com/v3/document_image/f182fab5-e14f-427a-9408-550277244f5f-18846868.jpg)

        - 当某用户程序要装入内存时，由操作系统内核程序根据用户程序大小检索该表，从中找到一个能满足大小的、未分配的分区，将之分配给该程序，然后修改状态为“已分配”

      - 优点：实现简单，无外部碎片。

      - 缺点：a. 当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能；b. 会产生内部碎片，内存利用率低。

    - 动态分区分配

      - 原理：
        - 动态分区分配又称为可变分区分配。这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统分区的大小和数目是可变的。

      - 方式：

        - 1、建表![img](https://api2.mubu.com/v3/document_image/65a1c628-b915-4d36-bb69-bb37d8bf88e8-18846868.jpg)

        - 2、分配

          

          - 首次适应算法

            - 算法思想：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。

            - 如何实现：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

          - 最佳适应算法

            - 算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。

            - 如何实现：空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

            - 缺点：每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。因此这种方法会产生很多的外部碎片。

          - 最 坏/大 适应算法

            - 算法思想：为了解决最佳适应算法的问题——即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。

            - 如何实现：空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

            - 缺点：每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有内存分区可用了。

          - 邻近适应算法

            - 算法思想：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

            - 如何实现：空闲分区以地址递增的顺序排列（可排成一个循环链表）。每次分配内存时从上次查找结束的位置开始查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

          - 归纳

            

            - 首次适应算法每次都要从头查找，每次都需要检索低地址的小分区。但是这种规则也决定了当低地址部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会更有可能把高地址部分的大分区保留下来（最佳适应算法的优点）

            - 邻近适应算法的规则可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，最后导致无大分区可用（最大适应算法的缺点）

            - 综合来看，四种算法中，首次适应算法的效果反而更好

        - 3、回收

          

          - 情况一：回收区有一个相邻的空闲分区，与相邻空闲分区合并

          - 情况二：回收区的前、后各有一个相邻的空闲分区，三个相邻的空闲分区合并为一个

          - 情况三：回收区的前、后都没有相邻的空闲分区，新增一个表项

  - 非连续分配：进程分配是一些分散的内存空间

    - 分页存储

      - 单级页表

        - 页面(进程)/页框(内存)

          - 将内存空间分为一个个大小相等的分区（比如：每个分区4KB），每个分区就是一个“页框”（页框=页帧=内存块=物理块=物理页面）。每个页框有一个编号，即“页框号”（页框号=页帧号=内存块号=物理块号=物理页号），页框号 从 0 开始 。

          - 将进程的逻辑地址空间也分为 与页框大小相等 的一个个部分，每个部分称为一个“页”或“页面” 。每个页面也有一个编号，即“页号”，页号也是 从 0 开始 。

          - 操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。

          - 各个页面不必连续存放，可以放到不相邻的各个页框中。

          - （注：进程的最后一个页面可能没有一个页框那么大。也就是说，分页存储有可能产生内部碎片，因此页框不能太大，否则可能产生过大的内部碎片造成浪费）

        - 页表

          - 页表映射![img](https://api2.mubu.com/v3/document_image/b893831b-0401-473c-a955-a87b3efd1642-18846868.jpg)

          - 快号![img](https://api2.mubu.com/v3/document_image/827bdbaf-daf5-40b4-a35b-797fc75a9ce5-18846868.jpg)

          - 页号：由于页号是隐含的，因此每个页表项占3B，存储整个页表至少需要 3*(n+1)B

        - 地址转换（逻辑地址  》物理地址）

          

          - 步骤：获取逻辑地址》除以页框大小》获得页号》页表查询页号相应页块》根据页号及偏移量即可轻松查询![img](https://api2.mubu.com/v3/document_image/65fe82e1-c888-4718-b1e1-7f38c8a50b9f-18846868.jpg)

          - 基本表（慢表）

            - 步骤：

              

              - 通常会在系统中设置一个页表寄存器（PTR），存放页表在内存中的起始地址F 和页表长度M。进程未执行时，页表的始址 和 页表长度 放在进程控制块（PCB）中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。

              - 逻辑地址》物理地址

                

                - 设页面大小为L，逻辑地址A到物理地址E的变换过程如下：

                - ①计算页号 P 和页内偏移量W（ 如果用十进制数手算，则 P=A/L，W=A%L；但是在计算机实际运行时，逻辑地址结构是固定不变的，因此计算机硬件可以更快地得到二进制表示的页号、页内偏移量）

                - ②比较页号P 和页表长度M，若 P≥M，则产生越界中断，否则继续执行。（注意：页号是从0开始的，而页表长度至少是1，因此 P=M 时也会越界）

                - ③页表中页号P对应的页表项地址 = 页表起始地址F + 页号P * 页表项长度，取出该页表项内容b，即为内存块号。（注意区分页表项长度、页表长度、页面大小的区别。页表长度指的是这个页表中总共有几个页表项，即总共有几个页；页表项长度指的是每个页表项占多大的存储空间；页面大小指的是一个页面占多大的存储空间）

                - ④计算 E = b * L + W，用得到的物理地址E 去访存。（如果内存块号、页面偏移量是用二进制表示的，那么把二者拼接起来就是最终的物理地址了）

            - 案例：![img](https://api2.mubu.com/v3/document_image/11b3eb0a-4542-4ac1-9120-7117769e03e4-18846868.jpg)

          - 快表

            - 快表：又称联想寄存器（TLB， translation lookaside buffer ），是一种访问速度比内存快很多的高速缓存，用来存放最近访问的页表项的副本，可以加速地址变换的速度。与此对应，内存中的页表常称为慢表。

            - 过程：

              

              - ① CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较。

              - ② 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表命中，则访问某个逻辑地址仅需一次访存即可。

              - ③ 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表未命中，则访问某个逻辑地址需要两次访存（注意：在找到页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换）

              - 由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间。因为局部性原理，一般来说快表的命中率可以达到 90% 以上。

            - 快表与慢表转换过程![img](https://api2.mubu.com/v3/document_image/ffb08dca-b562-4437-8ed2-b5ff86458901-18846868.jpg)

      - 两级页表

        - 作用：

          - 页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框。

          - 没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面。

        - 表（页目录表，二级页表）

          - 1、进行逻辑划分![img](https://api2.mubu.com/v3/document_image/6f2101e2-1e14-4d09-bcf9-d9f6804fbe6d-18846868.jpg)

          - 2、建表![img](https://api2.mubu.com/v3/document_image/74687bf7-34de-4f0e-ac66-8295cbb081f1-18846868.jpg)

        - 地址转换![img](https://api2.mubu.com/v3/document_image/a33113dc-6f31-4a1e-b002-b8820a73a5ca-18846868.jpg)

        - 页面调入内存![img](https://api2.mubu.com/v3/document_image/c798e145-36ff-4803-ae4c-89c4000d8eb4-18846868.jpg)

      - 多级页表
        - 若分为两级页表后，页表依然很长，则可以采用更多级页表，一般来说各级页表的大小不能超过一个页面![img](https://api2.mubu.com/v3/document_image/4e2672ce-9d13-4ba6-8620-1729d9c03e68-18846868.jpg)

    - 分段存储

      - 分配规则

        

        - 进程的地址空间：按照程序自身的逻辑关系划分为若干个段，每个段都有一个段名（在低级语言中，程序员使用段名来编程），每段从0开始编址

        - 内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻。

      - 段表![img](https://api2.mubu.com/v3/document_image/0827cf15-cbd7-4d37-841d-f49f65b24658-18846868.jpg)

      - 地址转换![img](https://api2.mubu.com/v3/document_image/e0af2c72-c5f5-43ae-ab5a-18b168e6f0c9-18846868.jpg)

      - 逻辑地址》物理地址![img](https://api2.mubu.com/v3/document_image/4441335c-07b4-4674-aa34-c3986af0fc28-18846868.jpg)

    - 分段与分页存储区别

      

      - 页是信息的物理单位。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的。

      - 段是信息的逻辑单位。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名。

      - 页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。

      - 分页的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址。

      - 分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址。

      - 分段比分页更容易实现信息的共享和保护![img](https://api2.mubu.com/v3/document_image/e2448cdf-3de1-476e-bdb2-88b082a97731-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/d19fc414-7fc7-4925-a555-26606b2e44ef-18846868.jpg)

      - 访问一个逻辑地址需要几次访存：

        - 分页（单级页表）：第一次访存——查内存中的页表，第二次访存——访问目标内存单元。总共两次访存

        - 分段：第一次访存——查内存中的段表，第二次访存——访问目标内存单元。总共两次访存与分页系统类似，分段系统中也可以引入快表机构，将近期访问过的段表项放到快表中，这样可以少一次访问，加快地址变换速度。

    - 段页式存储

      - 分配原理![img](https://api2.mubu.com/v3/document_image/1113fd56-7131-4096-908e-d15cdbd3db12-18846868.jpg)

      - 地址转换![img](https://api2.mubu.com/v3/document_image/bc5ddf81-9a6c-4553-95d0-52d1a306c42a-18846868.jpg)

      - 段表、页表![img](https://api2.mubu.com/v3/document_image/e08b02d7-2ac5-4f0d-a053-241b178bdb86-18846868.jpg)

      - 逻辑地址 》物理地址![img](https://api2.mubu.com/v3/document_image/bbe426c6-fe0d-4883-b0d8-4d890f115923-18846868.jpg)

  - 虚拟内存

    - 作用：（解决以下问题）

      - 作业必须一次性全部装入内存后才能开始运行。这会造成两个问题：

        - ①作业很大时，不能全部装入内存，导致大作业无法运行；

        - ②当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降。

      - 一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。

    - 原理：

      - 基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。

      - 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。

      - 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。

      - 在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存

    - 特征：

      - 多次性：无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存。

      - 对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出。

      - 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。

    - 请求分页管理方式
      - 页表![img](https://api2.mubu.com/v3/document_image/980c4a6f-ceb8-42de-ab5d-f09164475cb6-18846868.jpg)

    - 重要步骤：

      - 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序

        - 假设此时要访问逻辑地址=（页号，页内偏移量）=（0, 1024）

        - 在请求分页系统中，每当要访问的页面不在内存时，便产生一个缺页中断，然后由操作系统的缺页中断处理程序处理中断。

        - 此时缺页的进程阻塞，放入阻塞队列，调页完成后再将其唤醒，放回就绪队列。

        - 如果内存中有空闲块，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项。

        - 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存

    - 缺页中断及内存调入

      - 缺页中断：因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断一条指令在执行期间，可能产生多次缺页中断。![img](https://api2.mubu.com/v3/document_image/1365bfb1-2f58-4323-bfdb-61ecd9138048-18846868.jpg)

      - 步骤![img](https://api2.mubu.com/v3/document_image/d877b526-5b6c-401a-aba0-a8e9c1894b5a-18846868.jpg)

      - 在具有快表机构的请求分页系统中，访问一个逻辑地址时，若发生缺页，则地址变换步骤是：查快表(未命中)——查慢表(发现未调入内存)——调页(调入的页面对应的表项会直接加入快表)——查快表(命中)——访问目标内存单元

      - 细节：

        - ①只有“写指令”才需要修改“修改位”。并且，一般来说只需修改快表中的数据，只有要将快表项删除时才需要写回内存中的慢表。这样可以减少访存次数。

        - ②和普通的中断处理一样，缺页中断处理依然需要保留CPU现场。

        - ③需要用某种“页面置换算法”来决定一个换出页面（下节内容）

        - ④换入/换出页面都需要启动慢速的I/O操作，可见，如果换入/换出太频繁，会有很大的开销。

        - ⑤页面调入内存后，需要修改慢表，同时也需要将表项复制到快表中。

    - 页面置换算法

      

      - 最佳置换算法（OPT，Optimal）

        - 原理：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。![img](https://api2.mubu.com/v3/document_image/2f1758ea-73e8-4906-9227-b968b58e8eda-18846868.jpg)

        - 缺点：最佳置换算法可以保证最低的缺页率，但实际上，只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是无法实现的。

      - 先进先出置换算法（ FIFO ）

        - 原理：每次选择淘汰的页面是最早进入内存的页面

        - 实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可。队列的最大长度取决于系统为进程分配了多少个内存块。![img](https://api2.mubu.com/v3/document_image/06b2e198-9b96-4ff7-a86e-1c65812fe25c-18846868.jpg)

        - 缺点：

          - Belady 异常——当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。

          - 只有 FIFO 算法会产生 Belady 异常。另外，FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问。因此，算法性能差

      - 最近最久未使用置换算法（ LRU ）

        - 原理：每次淘汰的页面是最近最久未使用的页面

        - 实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t。当需要淘汰一个页面时，选择现有页面中 t 值最大的，即最近最久未使用的页面。![img](https://api2.mubu.com/v3/document_image/c5e396a9-43e8-4f65-818f-e4fe4b3910ba-18846868.jpg)

      - 时钟置换算法（ CLOCK ）

        - 原理：时钟置换算法是一种性能和开销较均衡的算法，又称CLOCK算法，或最近未用算法（NRU，NotRecently Used）

        - 简单的CLOCK 算法实现方法：为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。

          

          - 当某页被访问时，其访问位置为1。

          - 当需要淘汰一个页面时，只需检查页的访问位。如果是0，就选择该页换出；如果是1，则将它置为0，暂不换出，继续检查下一个页面

          - 若第一轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描（第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK 算法选择一个淘汰页面最多会经过两轮扫描）

        - 简单的时钟置换算法缺点：
          - 简单的时钟置换算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过，就不需要执行I/O操作写回外存。只有被淘汰的页面被修改过时，才需要写回外存。因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都相同时，应优先淘汰没有修改过的页面，避免I/O操作。这就是改进型的时钟置换算法的思想。修改位=0，表示页面没有被修改过；修改位=1，表示页面被修改过。

        - 改进型的时钟置换算法实现![img](https://api2.mubu.com/v3/document_image/d35483e2-e387-4116-8f34-38e04054712f-18846868.jpg)

    - 页面分配策略

      

      - 驻留集：指请求分页存储管理中给进程分配的物理块的集合。在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小

        - 若驻留集太小，会导致缺页频繁，系统要花大量的时间来处理缺页，实际用于进程推进的时间很少

        - 驻留集太大，又会导致多道程序并发度下降，资源利用率降低。所以应该选择一个合适的驻留集大

      - 固定分配：操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。即，驻留集大小不变
        - 系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。这种策略的缺点是：很难在刚开始就确定应为每个进程分配多少个物理块才算合理。（采用这种策略的系统可以根据进程大小、优先级、或是根据程序员给出的参数来确定为一个进程分配的内存块数）

      - 可变分配：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。即，驻留集大小可变

        - 全局置换：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程（只要缺页就给分配新物理块）
          - 刚开始会为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一块分配给该进程；若已无空闲物理块，则可选择一个未锁定的页面换出外存，再将该物理块分配给缺页的进程。采用这种策略时，只要某进程发生缺页，都将获得新的物理块，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出。被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少，缺页率会增加

        - 局部置换：发生缺页时只能选进程自己的物理块进行置换（要根据发生缺页的频率来动态地增加或减少进程的物理块）
          - 可变分配局部置换：刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度；反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。

      - 何时调入页面![img](https://api2.mubu.com/v3/document_image/d1e0f24a-d2c0-4282-9c12-40d53c2ab8d8-18846868.jpg)

      - 从何处调入页面

        - 1. 系统拥有足够的对换区空间：页面的调入、调出都是在内存与对换区之间进行，这样可以保证页面的调入、调出速度很快。在进程运行前，需将进程相关的数据从文件区复制到对换区。![img](https://api2.mubu.com/v3/document_image/838040a2-9da9-41fa-bb5e-0579c352e77b-18846868.jpg)

          

        - 2. 系统缺少足够的对换区空间：凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改，因此换出时不必写回磁盘，下次需要时再从文件区调入即可。对于可能被修改的部分，换出时需写回磁盘对换区，下次需要时再从对换区调入。![img](https://api2.mubu.com/v3/document_image/67bd625f-cf0d-42f6-a6b0-d27c615216da-18846868.jpg)

          

        - 3. UNIX 方式：运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。![img](https://api2.mubu.com/v3/document_image/e223f855-1110-4b35-89c9-74239dd0d97e-18846868.jpg)

          

      - 抖动（颠簸）现象：![img](https://api2.mubu.com/v3/document_image/a68c17a1-ea82-4770-86fe-212249b48255-18846868.jpg)

      - 工作集：指在某段时间间隔里，进程实际访问页面的集合。![img](https://api2.mubu.com/v3/document_image/61c40317-c743-428f-bbca-e802a906be2b-18846868.jpg)

- 内存空间的扩展

  - 覆盖技术

    - 原理：

      

      - 将程序分为多个段（多个模块），常用的段常驻内存，不常用的段在需要时调入内存

      - 内存中分为一个“固定区”和若干个“覆盖区”，需要常驻内存的段放在“固定区”中，调入后就不再调出（除非运行结束）

      - 不常用的段放在“覆盖区”，需要用到时调入内存，用不到时调出内存

    - 缺点：必须由程序员声明覆盖结构，操作系统完成自动覆盖。对用户不透明，增加了用户编程负担。覆盖技术只用于早期的操作系统中，现在已成为历史。

  - 交换技术

    - 原理：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存（进程在内存与磁盘间动态调度）

      - 1. 具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式；对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式（学过文件管理章节后即可理解）。总之，对换区的I/O速度比文件区的更快。![img](https://api2.mubu.com/v3/document_image/ae6ee2f5-c818-430c-80ad-a3ca12dae78c-18846868.jpg)

        

      - 2. 交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如：在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程；如果缺页率明显下降，就可以暂停换出。

        

      - 3. 可优先换出阻塞进程；可换出优先级低的进程；为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间

        

- 内存保护

  - 方法一：在CPU中设置一对上、下限寄存器，存放进程的上、下限地址。进程的指令要访问某个地址时，CPU检查是否越界。![img](https://api2.mubu.com/v3/document_image/01945a5e-f25b-4c08-b641-2ac5b7810ed0-18846868.jpg)

  - 方法二：采用重定位寄存器（又称基址寄存器）和界地址寄存器（又称限长寄存器）进行越界检查。重定位寄存器中存放的是进程的起始物理地址。界地址寄存器中存放的是进程的最大逻辑地址。![img](https://api2.mubu.com/v3/document_image/2f223a5e-50a2-4b3b-8dd3-fc0e7a8bcf31-18846868.jpg)

- 内存映射文件

  - 原理![img](https://api2.mubu.com/v3/document_image/1697272334387e3c3.jpg)

  - 归纳![img](./2、计算机操作系统.assets/1697272312641ea05.jpg)

# 文件管理

- 文件基本知识

  - 文件属性

    - 文件名：由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件。

    - 标识符：一个系统内的各文件标识符唯一，对用户来说毫无可读性，因此标识符只是操作系统用于区分各个文件的一种内部名称。

    - 类型：指明文件的类型

    - 位置：文件存放的路径（让用户使用）、在外存中的地址（操作系统使用，对用户不可见）

    - 大小：指明文件大小

    - 创建时间

    - 上次修改时间

    - 文件所有者信息

    - 保护信息：对文件进行保护的访问控制信息

  - 文件结构

    - 无结构文件：
      - 定义：文件内部的数据就是一系列二进制流或字符流组成。又称“流式文件”，如：“.txt”

    - 有结构文件：定由一组相似的记录组成，又称“记录式文件”。每条记录若干个数据项组成。如：数据库表文件。一般来说，每条记录有一个数据项可作为关键字。根据各条记录的长度（占用的存储空间）是否相等，又可分为定长记录和可变长记录两种。

    - 文件的逻辑结构：

      - 顺序文件：文件中的记录一个接一个地顺序排列（逻辑上），记录可以是定长的或可变长的。各个记录在物理上可以顺序存储或链式存储。

        - 顺序存储、链式存储![img](https://api2.mubu.com/v3/document_image/7c2e0d26-6ba9-4652-9335-08d897431e6b-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/9ed4788d-0dee-42b2-8c9a-219d30f7c5a8-18846868.jpg)

        - 定长记录和可变长记录![img](https://api2.mubu.com/v3/document_image/a9e39cce-4635-45dc-9e70-f9164e2043c4-18846868.jpg)

        - 定长记录的顺序文件，若物理上采用顺序存储，则可实现随机存取；若能再保证记录的顺序结构，则可实现快速检索（即根据关键字快速找到对应记录）

      - 索引文件：

        - 针对问题：对于可变长记录文件，要找到第 i 个记录，必须先顺序第查找前 i-1 个记录，但是很多应用场景中又必须使用可变长记录。

        - 索引表：![img](https://api2.mubu.com/v3/document_image/44d191f3-9071-402f-a338-d8ce32dbeb71-18846868.jpg)

      - 索引顺序文件：
        - 索引顺序文件是索引文件和顺序文件思想的结合。索引顺序文件中，同样会为文件建立一张索引表，但不同的是：并不是每个记录对应一个索引表项，而是一组记录对应一个索引表项。![img](https://api2.mubu.com/v3/document_image/2fda62ff-c538-4de3-8ed7-8adacf11a04d-18846868.jpg)

      - 多级索引顺序文件：（树）
        - 为了进一步提高检索效率，可以为顺序文件建立多级索引表![img](https://api2.mubu.com/v3/document_image/7ce18879-673b-4030-bc55-a6d4d8b1e144-18846868.jpg)

    - 文件的物理结构：

      - 文件块、磁盘块

        - 概述![img](https://api2.mubu.com/v3/document_image/10d3c1c9-8b65-470c-b777-e9a144dcfef0-18846868.jpg)

        - 逻辑地址到物理地址的映射![img](https://api2.mubu.com/v3/document_image/dedb2fde-63bb-4465-a255-7299beed2953-18846868.jpg)

      - 文件分配方式

        - 连续分配：连续分配方式要求每个文件在磁盘上占有一组连续的块

          

          - 优点：连续分配的文件在顺序读/写时速度最快

          - 缺点：

            - 物理上采用连续分配的文件不方便拓展![img](https://api2.mubu.com/v3/document_image/2339c25a-f052-4f50-a0e4-d0c384b68ffc-18846868.jpg)

            - 存储空间利用率低，会产生磁盘碎片![img](https://api2.mubu.com/v3/document_image/2bf9536c-7175-4973-a1c6-83e7840b2915-18846868.jpg)

        - 链接分配：采取离散分配的方式，可以为文件分配离散的磁盘块。分为隐式链接和显式链接两种

          - 隐式链接

            - 实现方式：![img](https://api2.mubu.com/v3/document_image/7aecc321-d6fd-4256-8955-eaf164026cc3-18846868.jpg)

            - 优点：采用隐式链接的链接分配方式，很方便文件拓展。另外，所有的空闲磁盘块都可以被利用，不会有碎片问题，外存利用率高。

            - 缺点：采用链式分配（隐式链接）方式的文件，只支持顺序访问，不支持随机访问，查找效率低。另外，指向下一个盘块的指针也需要耗费少量的存储空间

          - 显示链接

            - 实现方式![img](https://api2.mubu.com/v3/document_image/39e4b0d4-cbe9-46b7-930f-908cdaf5bb58-18846868.jpg)

            - 优点：

              - 采用链式分配（显式链接）方式的文件，支持顺序访问，也支持随机访问（想访问 i 号逻辑块时，并不需要依次访问之前的 0 ~ i-1号逻辑块），由于块号转换的过程不需要访问磁盘，因此相比于隐式链接来说，访问速度快很多。

              - 显式链接也不会产生外部碎片，也可以很方便地对文件进行拓展。

            - 缺点：
              - 文件分配表的需要占用一定的存储空间

        - 索引分配：索引分配允许文件离散地分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表中记录了文件的各个逻辑块对应的物理块

          - 索引表：

            - 功能类似于内存管理中的页表——建立逻辑页面到物理页之间的映射关系）

            - 索引表存放的磁盘块称为索引块，文件数据存放的磁盘块称为数据块

          - 实现方式：![img](https://api2.mubu.com/v3/document_image/faeaf92e-e1c3-4134-8aad-e3cf3c6aa146-18846868.jpg)

          - 逻辑块号到物理块号的转换：![img](https://api2.mubu.com/v3/document_image/d8c6f1a8-8f68-4daf-ae23-f31929cc3a5a-18846868.jpg)

          - 一个磁盘块装不下文件的整张索引表：

            - ①链接方案：如果索引表太大，一个索引块装不下，那么可以将多个索引块链接起来存放。![img](https://api2.mubu.com/v3/document_image/e83a7141-2fc7-4fe2-bfab-177a81c1dd21-18846868.jpg)

            - ②多层索引：建立多层索引（原理类似于多级页表）。使第一层索引块指向第二层的索引块。还可根据文件大小的要求再建立第三层、第四层索引块。![img](https://api2.mubu.com/v3/document_image/11a505a0-aa4b-462d-a7ea-f4023aa22f56-18846868.jpg)

            - ③混合索引：多种索引分配方式的结合。![img](https://api2.mubu.com/v3/document_image/a20a6729-2295-4256-ae7a-9b3e4aaee6f1-18846868.jpg)

  - 文件目录

    - 目录结构

      - 多级目录结构

        

        - 绝对路径：

        - 相对路径：

      - 无环图目录结构

        

        - 可以用不同的文件名指向同一个文件，甚至可以指向同一个目录（共享同一目录下的所有内容）

        - 需要为每个共享结点设置一个共享计数器，用于记录此时有多少个地方在共享该结点。用户提出删除结点的请求时，只是删除该用户的FCB、并使共享计数器减1，并不会直接删除共享结点

        - 只有共享计数器减为0时，才删除结点

        - 注意：共享文件不同于复制文件。在共享文件中，由于各用户指向的是同一个文件，因此只要其中一个用户修改了文件数据，那么所有用户都可以看到文件数据的变化

    - 文件控制块（FCB）

      

      - 文件的基本信息（文件名、物理地址、逻辑结构、物理结构等）

      - 存取控制信息（是否可读/可写、禁止访问的用户名单等）

      - 使用信息（如文件的建立时间、修改时间等）

    - 索引结点（FCB的改进）![img](https://api2.mubu.com/v3/document_image/605a615e-ee59-4533-bce7-e130c9e6f5ff-18846868.jpg)

  - 文件存储空间（分配与回收）

    - windows的存储空间的划分与初始化![img](https://api2.mubu.com/v3/document_image/6f152686-641d-45af-adae-c5bc4127203f-18846868.jpg)

    - 空闲表法：
      - 适用于 “连续分配方式”![img](https://api2.mubu.com/v3/document_image/5466901f-e694-44ef-b599-906122a62d32-18846868.jpg)

    - 空闲链表法：
      - 适用于离散分配的物理结构。为文件分配多个盘块时可能要重复多次操作![img](https://api2.mubu.com/v3/document_image/dec8f53e-721f-4bab-8d48-f22f0e111629-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/07eb329d-a7b4-4a78-ab73-48713db26b88-18846868.jpg)

    - 位示图法：

      - 连续分配、离散分配都适用![img](https://api2.mubu.com/v3/document_image/566ee7ac-93de-451a-9939-9c7f3b259b80-18846868.jpg)

      - 分配与回收![img](https://api2.mubu.com/v3/document_image/596a6084-604c-4a36-aa2c-94e7533627d1-18846868.jpg)

    - 成组链接法：

      - 意义：

        - 空闲表法、空闲链表法不适用于大型文件系统，因为空闲表或空闲链表可能过大。UNIX系统中采用了成组链接法对磁盘空闲块进行管理。

        - 文件卷的目录区中专门用一个磁盘块作为“超级块”，当系统启动时需要将超级块读入内存。并且要保证内存与外存中的“超级块”数据一致。![img](https://api2.mubu.com/v3/document_image/918c9fd4-09da-4940-8ca7-5de33f555e38-18846868.jpg)

      - 原理：

        - 1、空闲区：首个表示空闲盘块数量，第二个表示下一个盘块区![img](https://api2.mubu.com/v3/document_image/7f93ce43-05ff-422c-9c9d-a0e6be6bd415-18846868.jpg)

        - 2、分配：![img](https://api2.mubu.com/v3/document_image/1e4b49f8-404d-4bd6-9dc6-c7de0d0997df-18846868.jpg)

        - 3、回收：![img](https://api2.mubu.com/v3/document_image/be614f5d-f23c-4e0d-8eb0-a23b81ec0cc1-18846868.jpg)

- 文件基本功能

  

  - 创建文件：

    

    - 进行 Create 系统调用时，需要提供的几个主要参数：

      - 1. 所需的外存空间大小（如：一个盘块，即1KB）

        

      - 2. 文件存放路径（“D:/Demo”）

        

      - 3. 文件名（这个地方默认为“新建文本文档.txt”）

        

    - 操作系统在处理 Create 系统调用时，主要做了两件事：

      - 1. 在外存中找到文件所需的空间（结合上小节学习的空闲链表法、位示图、成组链接法等管理策略，找到空闲空间）

        

      - 2. 根据文件存放路径的信息找到该目录对应的目录文件（此处就是 D:/Demo 目录），在目录中创建该文件对应的目录项。目录项中包含了文件名、文件在外存中的存放位置等信息。

        

  - 删除文件：![img](https://api2.mubu.com/v3/document_image/5d9681dc-a27d-4274-80fa-1ab017c69d6f-18846868.jpg)

  - 打开文件

    - 步骤![img](https://api2.mubu.com/v3/document_image/4755311b-a79b-43bd-9f3c-5bb5e09fbfe5-18846868.jpg)

    - 表![img](https://api2.mubu.com/v3/document_image/2e3e4df5-6024-4b2b-aba0-c72441619121-18846868.jpg)

  - 关闭文件![img](https://api2.mubu.com/v3/document_image/dc6a3f43-abd5-42f9-bca5-03256756a0db-18846868.jpg)

  - 读文件![img](https://api2.mubu.com/v3/document_image/88ba20c0-f6f0-465c-9962-a0acd182bb6d-18846868.jpg)

  - 写文件![img](https://api2.mubu.com/v3/document_image/f532f456-e7bb-405c-9c08-3eb19a3b3d88-18846868.jpg)

- 文件重要功能

  - 文件共享（多个用户共享同一个文件）

    - 基于索引结点的共享方式（硬链接）![img](https://api2.mubu.com/v3/document_image/8a98015d-706a-4745-9422-1487bc3eec79-18846868.jpg)

    - 基于符号链的共享方式（软链接）（win的快捷方式，记录路径）![img](https://api2.mubu.com/v3/document_image/c1200de5-be71-461f-b366-9f745d45bd97-18846868.jpg)

  - 文件保护

    - 口令保护![img](https://api2.mubu.com/v3/document_image/86a41033-fbf3-470f-924c-9a8a73a64e0c-18846868.jpg)

    - 加密保护：使用某个“密码”对文件进行加密，在访问文件时需要提供正确的“密码”才能对文件进行正确的解密。

      - 异或加密![img](https://api2.mubu.com/v3/document_image/1950e003-2f4c-4072-bba1-e7c452783934-18846868.jpg)

      - 优点：保密性强，不需要在系统中存储“密码”

      - 缺点：编码/译码，或者说加密/解密要花费一定时间。

    - 访问控制：在每个文件的FCB（或索引结点）中增加一个访问控制列表（Access-Control List, ACL），该表中记录了各个用户可以对该文件执行哪些操作。

      - 访问类型![img](https://api2.mubu.com/v3/document_image/f53cc61f-5b39-4c13-8389-e022ea0c9169-18846868.jpg)

      - 组![img](https://api2.mubu.com/v3/document_image/9d7cbe39-ac71-46bd-a2b0-155fe6e01ae1-18846868.jpg)

- 文件系统结构

  - 层次结构

    

    - 案例：![img](https://api2.mubu.com/v3/document_image/5f376dcc-dd3b-4369-873b-2539ca5f64ad-18846868.jpg)

  - 全局结构

    - 物理格式化![img](https://api2.mubu.com/v3/document_image/16975085015501f5c.jpg)

    - 逻辑格式化![img](https://api2.mubu.com/v3/document_image/1697508501550c756.jpg)

    - open系统调用![img](https://api2.mubu.com/v3/document_image/1697508501550e858.jpg)

- 虚拟文件系统：[Linux虚拟文件系统 ](https://zhuanlan.zhihu.com/p/69289429)

# 磁盘管理

- 磁盘

  - 结构

    - 磁盘、磁道、扇区![img](https://api2.mubu.com/v3/document_image/76c27048-119d-4f9a-841f-71f151dc6779-18846868.jpg)

    - 盘面、柱面![img](https://api2.mubu.com/v3/document_image/80003a2f-db3c-496d-8a7a-3f9c786d008b-18846868.jpg)

    - 磁盘的物理地址![img](https://api2.mubu.com/v3/document_image/93c711c5-192f-4700-ae4b-2d9a4a733901-18846868.jpg)

    - 磁盘的分类![img](https://api2.mubu.com/v3/document_image/168a6487-2aa1-4882-a245-bbffe63f9539-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/2fbb6940-03a6-4b86-b815-43b87e24aff7-18846868.jpg)

  - 在磁盘中读 / 写数据
    - 需要把“磁头”移动到想要读/写的扇区所在的磁道。磁盘会转起来，让目标扇区从磁头下面划过，才能完成对扇区的读/写操作。

  - 一次磁盘读 / 写操作需要的时间

    - 寻找时间（寻道时间）T S ：在读/写数据前，将磁头移动到指定磁道所花的时间。

      - ①启动磁头臂是需要时间的。假设耗时为 s；

      - ②移动磁头也是需要时间的。假设磁头匀速移动，每跨越一个磁道耗时为 m，总共需要跨越 n 条磁道。则：寻道时间 T S = s + m*n

    - 延迟时间T R ：通过旋转磁盘，使磁头定位到目标扇区所需要的时间。设磁盘转速为 r （单位：转/秒，或 转/分），则平均所需的延迟时间 T R = (1/2)*(1/r) = 1/2r

    - 传输时间T t ：从磁盘读出或向磁盘写入数据所经历的时间，假设磁盘转速为 r，此次读/写的字节数为 b，每个磁道上的字节数为 N。则：传输时间T t = (1/r) * (b/N) = b/(rN）

    - 总的平均存取时间 T a = T S + 1/2r + b/(rN)

  - 磁盘调度算法

    

    - 先来先服务算法（ FCFS ）![img](https://api2.mubu.com/v3/document_image/ae1fa339-ec5f-4f67-97e1-ce66bda8cda1-18846868.jpg)

    - 最短寻找时间优先（ SSTF ）![img](https://api2.mubu.com/v3/document_image/6d4a5f5c-4c6d-447a-8a24-ed158c92759c-18846868.jpg)

    - 扫描算法（ SCAN ）![img](https://api2.mubu.com/v3/document_image/fdd48fe9-29b2-4833-99a8-1a066c0a8592-18846868.jpg)

    - LOOK 调度算法![img](https://api2.mubu.com/v3/document_image/134e33ad-26aa-4310-b4cb-ab09d14db4ad-18846868.jpg)

    - 循环扫描算法（ C-SCAN ）![img](https://api2.mubu.com/v3/document_image/c8574424-4718-4642-96d7-673f42645505-18846868.jpg)

    - C-LOOK 调度算法![img](https://api2.mubu.com/v3/document_image/9f8c84c8-e1ea-4e2a-99a2-d997eae12578-18846868.jpg)

  - 减少延迟时间

    

    - 概述![img](https://api2.mubu.com/v3/document_image/b83b6c55-18af-42fd-98ea-0e29070a325c-18846868.jpg)

    - 交替编号![img](https://api2.mubu.com/v3/document_image/942f6e92-ac14-41c2-9675-7ac35d7aa1b0-18846868.jpg)

    - 错位命名![img](https://api2.mubu.com/v3/document_image/ef6fb0a0-3626-4bc2-89f8-8cf16e19a83c-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/d3999178-1c1e-47f6-98aa-665c641d3888-18846868.jpg)

  - 磁盘初始化![img](https://api2.mubu.com/v3/document_image/f9f9ecdd-4e43-4847-a01e-a8b0927d793e-18846868.jpg)

  - 引导块![img](https://api2.mubu.com/v3/document_image/488b4af7-f76b-463b-b7f6-f9f86f1029e4-18846868.jpg)

  - 坏块的管理![img](https://api2.mubu.com/v3/document_image/9e0dac72-9c5f-4b53-95c5-f12b2dc29576-18846868.jpg)

- 固态硬盘![img](./2、计算机操作系统.assets/16975494874181d96.jpg)

# IO管理

- IO设备：

  - I/O 设备就是可以将数据输入到计算机，或者可以接收计算机输出数据的外部设备，属于计算机中的硬件部件。

  - UNIX系统将外部设备抽象为一种特殊的文件，用户可以使用与文件操作相同的方式对外部设备进行操作。

- 分类

  - 特性![img](https://api2.mubu.com/v3/document_image/d31e4353-3858-4953-8cc4-e759ae8a1b0c-18846868.jpg)

  - 传输速率![img](https://api2.mubu.com/v3/document_image/4dbd8462-733d-401e-93a1-0c9ee60be46b-18846868.jpg)

  - 信息交换的单位![img](https://api2.mubu.com/v3/document_image/f2a4d9ab-29e9-43e7-a9d9-20f4a31934c1-18846868.jpg)

- 部件

  - 机械部件：

    - I/O设备的机械部件主要用来执行具体I/O操作。

    - 如我们看得见摸得着的鼠标/键盘的按钮；显示器的LED屏；移动硬盘的磁臂、磁盘盘面。

  - 电子部件：

    - I/O设备的电子部件通常是一块插入主板扩充槽的印刷电路板

    - CPU无法直接控制I/O设备的机械部件，因此I/O设备还要有一个电子部件作为CPU和I/O设备机械部件之间的“中介”，用于实现CPU对设备的控制。

    - 这个电子部件就是I/O控制器，又称设备控制器。CPU可控制I/O控制器，又由I/O控制器来控制设备的机械部件。

- I/O 控制器（CPU和I/O设备机械部件之间的“中介”）

  - 功能![img](https://api2.mubu.com/v3/document_image/1f4f433b-faa5-49ed-8965-4d316a34a3c8-18846868.jpg)

  - 组成

    

    - 数据寄存器、控制寄存器、状态寄存器可能有多个（如：每个控制/状态寄存器对应一个具体的设备），且这些寄存器都要有相应的地址，才能方便CPU操作。有的计算机会让这些寄存器占用内存地址的一部分，称为内存映像I/O；另一些计算机则采用I/O专用地址，即寄存器独立编址![img](https://api2.mubu.com/v3/document_image/d62c3999-8ebe-4362-839e-829df363c998-18846868.jpg)

  - I/O控制方式

    - 程序直接控制方式

      - 1. 完成一次读/写操作的流程![img](https://api2.mubu.com/v3/document_image/de5d3856-2042-40d7-808f-f2a9f598015a-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/13b0523a-fa41-4a51-b3a6-4bae234f8d10-18846868.jpg)

        

      - 2. CPU干预的频率

        - 很频繁，I/O操作开始之前、完成之后需要CPU介入，并且在等待I/O完成的过程中CPU需要不断地轮询检查。

      - 3. 数据传送的单位每次读/写一个字

        

      - 4. 数据的流向

        - 读操作（数据输入）：I/O设备àCPUà内存

        - 写操作（数据输出）：内存àCPUàI/O设备

        - 每个字的读/写都需要CPU的帮助

      - 5. 主要缺点和主要优点

        - 优点：实现简单。在读/写指令之后，加上实现循环检查的

        - 缺点：CPU和I/O设备只能串行工作，CPU需要一直轮询检查，长期处于“忙等”状态 ，CPU利用率低。

    - 中断驱动方式

      - 概述![img](https://api2.mubu.com/v3/document_image/bcb49a17-7034-4148-aad7-5a949bd54344-18846868.jpg)

      - 归纳![img](https://api2.mubu.com/v3/document_image/a1d8e5f8-79f3-4f6f-9ba3-d8a8d393b318-18846868.jpg)

    - DMA 方式

      - 概述![img](https://api2.mubu.com/v3/document_image/c4c01209-f8f2-4bc9-abcc-a6251a292ba7-18846868.jpg)

      - 存储器![img](https://api2.mubu.com/v3/document_image/649dda71-b66e-40b5-b1b7-439be50b7ee3-18846868.jpg)

      - 归纳![img](https://api2.mubu.com/v3/document_image/dd47258a-d8c5-478b-a8a4-1bfd8f8fc2e6-18846868.jpg)

    - 通道控制方式

      - 通道：一种硬件，可以理解为是 “弱鸡版的CPU”。通道可以识别并执行一系列通道指令![img](https://api2.mubu.com/v3/document_image/5a7529c7-ce1b-456b-ad86-e6dca49493ba-18846868.jpg)

      - 归纳![img](https://api2.mubu.com/v3/document_image/def63f81-667b-4b12-805a-d95af8680213-18846868.jpg)

  - I/O软件层次结构

    

    - 用户层软件![img](https://api2.mubu.com/v3/document_image/6e19a7f5-1de4-4485-88e1-d9067dfc220b-18846868.jpg)

    - 设备独立性软件：与设备的硬件特性无关的功能几乎都在这一层实现

      - ①向上层提供统一的调用接口（如 read/write 系统调用）

      - ②设备的保护：原理类似与文件保护。设备被看做是一种特殊的文件，不同用户对各个文件的访问权限是不一样的，同理，对设备的访问权限也不一样。

      - ③差错处理：设备独立性软件需要对一些设备的错误进行处理

      - ④设备的分配与回收

      - ⑤数据缓冲区管理：可以通过缓冲技术屏蔽设备之间数据交换单位大小和传输速度的差异

      - ⑥建立逻辑设备名到物理设备名的映射关系；根据设备类型选择调用相应的驱动程序![img](https://api2.mubu.com/v3/document_image/92376ed5-2f30-4c6c-a070-017e2fd3fc0c-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/74ea0919-9681-495c-9c37-01ba8b580173-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/c7afcfd0-5c65-4d12-811f-570d35fcc114-18846868.jpg)

    - 设备驱动程序接口

    - 设备驱动程序![img](https://api2.mubu.com/v3/document_image/9243a2c0-8c67-4290-b16a-437831ac8811-18846868.jpg)

    - 中断处理程序![img](https://api2.mubu.com/v3/document_image/b58e689c-705d-4f2e-ab4f-0bf68cf4cedf-18846868.jpg)

  - 假脱机技术
    - 脱机技术

- 缓冲区

  - 定义

    - 缓冲区是一个存储区域，可以由专门的硬件寄存器组成，也可利用内存作为缓冲区。

    - 使用硬件作为缓冲区的成本较高，容量也较小，一般仅用在对速度要求非常高的场合（如存储器管理中所用的联想寄存器，由于对页表的访问频率极高，因此使用速度很快的联想寄存器来存放页表项的副本）

    - 一般情况下，更多的是利用内存作为缓冲区，“设备独立性软件”的缓冲区管理就是要组织管理好这些缓冲区

  - 作用![img](https://api2.mubu.com/v3/document_image/52d6beb0-58f1-4a3d-8aba-ab0d2da125f1-18846868.jpg)

  - 单缓冲

    - 假设某用户进程请求某种块设备读入若干块的数据。若采用单缓冲的策略，操作系统会在主存中为其分配一个缓冲区（若题目中没有特别说明，一个缓冲区的大小就是一个块）。

    - 注意：当缓冲区数据非空时，不能往缓冲区冲入数据，只能从缓冲区把数据传出；当缓冲区为空时，可以往缓冲区冲入数据，但必须把缓冲区充满以后，才能从缓冲区把数据传出。![img](https://api2.mubu.com/v3/document_image/78f9fa9f-140e-481f-94fa-4f801b757da8-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/12e982d7-3dea-4cb6-9f87-517c0a5ef5ef-18846868.jpg)

  - 双缓冲
    - 假设某用户进程请求某种块设备读入若干块的数据。若采用双缓冲的策略，操作系统会在主存中为其分配两个缓冲区（若题目中没有特别说明，一个缓冲区的大小就是一个块）![img](https://api2.mubu.com/v3/document_image/eab86480-2a53-47e1-adec-41fc04196b11-18846868.jpg)![img](https://api2.mubu.com/v3/document_image/7d3bbb31-9521-4350-8b73-9f8bed70d7d6-18846868.jpg)

  - 单 / 双缓冲在通信时的区别

    - 若两个相互通信的机器只设置单缓冲区，在任一时刻只能实现数据的单向传输

    - 若两个相互通信的机器设置双缓冲区，则同一时刻可以实现双向的数据传输

  - 循环缓冲区
    - 将多个大小相等的缓冲区链接成一个循环队列![img](https://api2.mubu.com/v3/document_image/26958261-813b-4be9-83cc-db3eeae66ad2-18846868.jpg)

  - 缓冲池

    - 缓冲池由系统中共用的缓冲区组成。这些缓冲区按使用状况可以分为：空缓冲队列、装满输入数据的缓冲队列（输入队列）、装满输出数据的缓冲队列（输出队列）。

    - 另外，根据一个缓冲区在实际运算中扮演的功能不同，又设置了四种工作缓冲区：用于收容输入数据的工作缓冲区（hin）、用于提取输入数据的工作缓冲区（sin）、用于收容输出数据的工作缓冲区（hout）、用于提取输出数据的工作缓冲区（sout）

      

      - ①输入进程请求输入数据
        - 从空缓冲队列中取出一块作为收容输入数据的工作缓冲区（hin）。冲满数据后将缓冲区挂到输入队列队尾

      - ②计算进程想要取得一块输入数据
        - 从输入队列中取得一块冲满输入数据的缓冲区作为“提取输入数据的工作缓冲区（sin）”。缓冲区读空后挂到空缓冲区队列

      - ③计算进程想要将准备好的数据冲入缓冲区
        - 从空缓冲队列中取出一块作为“收容输出数据的工作缓冲区（hout）”。数据冲满后将缓冲区挂到输出队列队尾

      - ④输出进程请求输出数据
        - 从输出队列中取得一块冲满输出数据的缓冲区作为“提取输出数据的工作缓冲区（sout）”。缓冲区读空后挂到空缓冲区队列



## I/O

1. 阻塞式 I/O 模型（Blocking I/O Model）：在执行 I/O 操作时，线程会被阻塞，直到数据准备就绪或操作完成。
2. 非阻塞式 I/O 模型（Non-blocking I/O Model）：在执行 I/O 操作时，线程不会被阻塞，而是立即返回，可以继续执行其他任务。需要轮询或者多路复用来检查是否有数据就绪。
3. I/O 复用模型（I/O Multiplexing Model）：通过一种机制（如 select、poll、epoll 等）来同时监视多个 I/O 事件，当有事件发生时，通知程序进行处理。典型代表是 epoll。
4. 信号驱动 I/O 模型（Signal-driven I/O Model）：当 I/O 操作完成时，操作系统向应用程序发送一个信号，应用程序收到信号后进行相应处理。
5. 异步 I/O 模型（Asynchronous I/O Model）：在发起一个 I/O 操作后，可以立即返回继续执行其他任务，当操作完成时，操作系统通知应用程序，数据已经准备好了。常见的是使用回调函数来处理完成事件。